---
id: llm-providers
title: LLM Providers
---

import { ScreenshotWrapper } from '../shared/_ScreenshotWrapper';


The Tolgee platform allows you to set up custom LLM models. You can do so in the organization section
(Cloud version) or globally in the server configuration (Self-hosted version).

In this guide, we'll show setup via the UI, but the fields are mostly identical when you use the server
configuration.

## Configuration via UI

  1. Go to Organization settings
  2. Select LLM Providers in the side menu

<ScreenshotWrapper
  src="/img/docs/platform/llm-providers/llm-providers-list.png"
  alt="new member invitation"
/>

Here, you can see a list of custom providers (configuration is per Organization). You can also see
server-configured providers in the `Server` tab. Server providers cannot be modified via UI.

## Adding custom provider

Click the `+ Provider` button to open a provider dialog.

<ScreenshotWrapper
  src="/img/docs/platform/llm-providers/llm-provider-create.png"
  alt="new member invitation"
/>

### Provider naming

The provider name is displayed in the UI, as well as the provider's ID.

If you name a custom provider with the same name as a server provider, you will override it.

If you specify multiple providers with the same name, Tolgee will assume it's the same provider with multiple
deployments, so there will be a load balance between them.

You can also specify `Priority`:
 - LOW - deployment will only be used for batch operations
 - HIGH - deployment will only be used for suggestions

This is useful for load-balancing and avoiding rate limits.

## Provider types

Provider type selects a type of API; it influences what other configuration fields are available
based on the API requirements.

### Open AI

It is designed to work with the official OpenAI API.

 - `API url`: e.g. "https://api.openai.com"
 - `API key`: specify your OpenAI API key without the `Bearer ` prefix
 - `Model`: specify your model name, e.g. "gpt-4o"
 - `Format`: some older models don't support structured output, but for newer ones, select "json_schema"

#### Using Open AI API of LM studio

[LM studio](https://lmstudio.ai/) uses OpenAI compatible API, so you can configure Tolgee to use it.

Example configuration:
 - `API url`: "http://localhost:1234" (default when running lm studio locally)
 - `API key`: empty
 - `Model`: "gemma-3-4b-it-qat" (name of the model in the lm studio)
 - `Format`: some older models don't support structured output, but for newer ones, select "json_schema"


### Azure Open AI

It is designed to work with the Azure version of OpenAI API.

 - `API url`: URL of your Azure resource
 - `API key`: resource key
 - `Deployment`: specify your AI Foundry deployment (e.g., gpt-4o)
 - `Format`: some older models don't support structured output, but for newer ones, select "json_schema"


## Deleting or editing provider

Click on the`â‹®` icon next to a provider.

From here, you can select `Edit` or `Delete`.

<ScreenshotWrapper
  src="/img/docs/platform/llm-providers/llm-providers-edit-delete.png"
  alt="new member invitation"
/>

